{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/schwaaweb/aimlds1_11-NLP/blob/master/T11_CC_DJ_Genism_NLP_Coding_Challenge__2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qd1ltfV8QShV"
   },
   "source": [
    "### Coding Challenge #2: Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iWWDecybQ1zz"
   },
   "source": [
    "A common task in NLP is to determine the similarity between documents or words. In order to facilitate the comparison between documents or words, you will leverage the learnings from Coding Challenge #1 to create vectors. Once you have a document term matrix, comparisons are possible since you can measure the difference between the numbers.\n",
    "\n",
    "In this Coding Challenge, you will utilize the \"**Gensim**\" library, which is a free Python library to determine document similarity.\n",
    "\n",
    "**\"Gensim\" Reference**: https://radimrehurek.com/project/gensim/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c3hSkp0srSXR"
   },
   "source": [
    "**Install Gensim**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tEPlGPVSrZv6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/darwinm/anaconda3\n",
      "\n",
      "  added / updated specs: \n",
      "    - gensim\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    smart_open-1.5.7           |           py36_0          58 KB  anaconda\n",
      "    boto3-1.7.32               |           py36_0         110 KB  anaconda\n",
      "    bz2file-0.98               |           py36_0          12 KB  anaconda\n",
      "    certifi-2018.4.16          |           py36_0         142 KB  anaconda\n",
      "    openssl-1.0.2o             |       h26aff7b_0         3.4 MB  anaconda\n",
      "    conda-4.5.4                |           py36_0         1.0 MB  anaconda\n",
      "    s3transfer-0.1.13          |           py36_0          76 KB  anaconda\n",
      "    ca-certificates-2018.03.07 |                0         124 KB  anaconda\n",
      "    botocore-1.10.32           |           py36_0         3.1 MB  anaconda\n",
      "    gensim-3.4.0               |   py36h917ab60_0        21.5 MB  anaconda\n",
      "    jmespath-0.9.3             |   py36h767a2d6_0          34 KB  anaconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        29.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    boto3:           1.7.32-py36_0        anaconda   \n",
      "    botocore:        1.10.32-py36_0       anaconda   \n",
      "    bz2file:         0.98-py36_0          anaconda   \n",
      "    gensim:          3.4.0-py36h917ab60_0 anaconda   \n",
      "    jmespath:        0.9.3-py36h767a2d6_0 anaconda   \n",
      "    s3transfer:      0.1.13-py36_0        anaconda   \n",
      "    smart_open:      1.5.7-py36_0         anaconda   \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    certifi:         2018.4.16-py36_0     conda-forge --> 2018.4.16-py36_0  anaconda\n",
      "    conda:           4.5.4-py36_0         conda-forge --> 4.5.4-py36_0      anaconda\n",
      "    openssl:         1.0.2o-0             conda-forge --> 1.0.2o-h26aff7b_0 anaconda\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "    ca-certificates: 2018.4.16-0          conda-forge --> 2018.03.07-0      anaconda\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "smart_open-1.5.7     |   58 KB | ####################################### | 100% \n",
      "boto3-1.7.32         |  110 KB | ####################################### | 100% \n",
      "bz2file-0.98         |   12 KB | ####################################### | 100% \n",
      "certifi-2018.4.16    |  142 KB | ####################################### | 100% \n",
      "openssl-1.0.2o       |  3.4 MB | ####################################### | 100% \n",
      "conda-4.5.4          |  1.0 MB | ####################################### | 100% \n",
      "s3transfer-0.1.13    |   76 KB | ####################################### | 100% \n",
      "ca-certificates-2018 |  124 KB | ####################################### | 100% \n",
      "botocore-1.10.32     |  3.1 MB | ####################################### | 100% \n",
      "gensim-3.4.0         | 21.5 MB | ####################################### | 100% \n",
      "jmespath-0.9.3       |   34 KB | ####################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "CPU times: user 8.05 s, sys: 5.08 s, total: 13.1 s\n",
      "Wall time: 5min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# https://radimrehurek.com/gensim/install.html\n",
    "#!pip install --upgrade gensim\n",
    "!conda install -c anaconda gensim --yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56qjZ1IzsO54"
   },
   "source": [
    "**Install NLTK:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kfVsL9M9sSMJ"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Import the NLTK package\n",
    "import nltk\n",
    "\n",
    "# Get all the data associated with NLTK â€“ could take a while to download all the data\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CC68LogGscTI"
   },
   "source": [
    "**Import the requiste NLTK packages:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lt_gawHGsbrB"
   },
   "outputs": [],
   "source": [
    "#Import word tokenizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hj_FUsxPtDOI"
   },
   "source": [
    "**Dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kM4qHcNWs1__"
   },
   "outputs": [],
   "source": [
    "#For the purposes of this challenge, each line represents a document. In all, there are 8 documents\n",
    "\n",
    "raw_documents = ['The dog ran up the steps and entered the owner\\'s room to check if the owner was in the room.',\n",
    "             'My name is Thomson Comer, commander of the Machine Learning program at Lambda school.',\n",
    "             'I am creating the curriculum for the Machine Learning program and will be teaching the full-time Machine Learning program.',\n",
    "            'Machine Learning is one of my favorite subjects.',\n",
    "            'I am excited about taking the Machine Learning class at the Lambda school starting in April.',\n",
    "                'When does the Machine Learning program kick-off at Lambda school?',\n",
    "                'The batter hit the ball out off AT&T park into the pacific ocean.',\n",
    "                'The pitcher threw the ball into the dug-out.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKGw63jmrjLg"
   },
   "source": [
    "**Step #1**: **Create a document that contains a list of tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fU5v8oM3t2nx"
   },
   "outputs": [],
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JjAxAZXTt45S"
   },
   "source": [
    "**Step #2: Use the document to create a dictionary - a dictionary maps every word to a number**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9w477lVuIfs"
   },
   "outputs": [],
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Q1E2EONvRlB"
   },
   "source": [
    "**Step #3: Convert the list of tokens from the document (created above in Step 1) into a bag of words. The bag of words highlights the term frequency i.e. each element in the bag of words is the index of the word in the dictionary and the # of times it occurs**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zfIFJT0Lv0an"
   },
   "outputs": [],
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f9rsM5d1xH2T"
   },
   "source": [
    "**Step #4:  Use the \"*Gensim*\" library to create a TF-IDF module for the bag of words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tyg_GwYEekgH"
   },
   "outputs": [],
   "source": [
    " # Step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfmg609ue5B0"
   },
   "source": [
    "**Step #5: a) Output the 5th document, b) Output the bag of words for the fifth document i.e. term frequency, c) Review the Inter Document Frequency (IDF) for each term in the bag of words for the 5th document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C330my8hfokU"
   },
   "outputs": [],
   "source": [
    "# Step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7hP1HRC-gUEf"
   },
   "source": [
    "**Step #6: Determine document similarity** -  Identify the most similar document and the least similar document to the body of text below.\n",
    "\n",
    "*Good Reference for review*: https://radimrehurek.com/gensim/similarities/docsim.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VVyDyZ9ThkGI"
   },
   "outputs": [],
   "source": [
    "# Step 6\n",
    "\n",
    "# Document to  compare: \"Machine Learning at Lambda school is awesome\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "T11_CC--DJ--Genism-NLP_Coding_Challenge_#2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
